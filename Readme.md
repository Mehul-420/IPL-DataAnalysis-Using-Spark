# IPL Data Analysis Using Spark

This project showcases the implementation of Apache Spark for analyzing the IPL dataset from 2008 to 2017. The analysis is based on the paper "Big Data Analytics Using Apache Spark – A Case Study of Predicting Player Performance in the Indian Premier League (IPL)".

## Project Overview

The goal of this project is to demonstrate the capabilities of Apache Spark in handling and analyzing large datasets. The IPL dataset used in this project includes match data from the Indian Premier League (IPL) spanning from 2008 to 2017.

## Dataset

The dataset contains detailed information about IPL matches, including scores, player performances, and match outcomes. It is used to perform various analyses and derive insights about player performance and team strategies. The dataset can be accessed here.

## Implementation

The implementation is done using Apache Spark, a powerful open-source processing engine for big data. The code for this project can be found in the Jupyter Notebook IPL Data Analysis.ipynb.

## Key Features

- Data Cleaning and Preprocessing
- Exploratory Data Analysis (EDA)
- Player Performance Analysis
- Team Performance Analysis
- Predictive Modeling

## Package Requirements

#For offline implementaion

- Python >= 3.7
- Scala
- Hadoop
- JDK
- Spark
- Anaconda
#For online implementaion  
- Databricks
- AWS S3 Bucket (for storage of Datasets(can also store dataset in Databrics ))

## How to Run

1. Clone the repository:
    ```bash
    git clone https://github.com/Mehul-420/IPL-DataAnalysis-Using-Spark.git
    ```
2. Navigate to the project directory:
    ```bash
    cd IPL-DataAnalysis-Using-Spark
    ```
3. Open the Jupyter Notebook:
    ```bash
    jupyter notebook "IPL Data Analysis.ipynb"
    ```

## References

-Salloum, S., Dautov, R., Chen, X. et al. Big data analytics on Apache Spark. Int J Data Sci Anal 1, 145–164 (2016). https://doi.org/10.1007/s41060-016-0027-9

